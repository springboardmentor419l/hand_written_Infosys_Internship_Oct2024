{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vcE9kEfQaYC"
      },
      "outputs": [],
      "source": [
        "# creating input and kernel tensor\n",
        "import torch\n",
        "\n",
        "# Input tensor\n",
        "input_tensor = torch.tensor([[1, 1, 1, 0, 0, 0],\n",
        "                            [1, 1, 1, 0, 0, 0],\n",
        "                            [1, 1, 1, 0, 0, 0],\n",
        "                            [1, 1, 1, 0, 0, 0],\n",
        "                            [1, 1, 1, 0, 0, 0],\n",
        "                            [1, 1, 1, 0, 0, 0]])\n",
        "\n",
        "# Kernel tensor (for detecting vertical edges)\n",
        "kernel = torch.tensor([[-1, 0, 1],\n",
        "                        [-1, 0, 1],\n",
        "                        [-1, 0, 1]])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convolution with different strides\n",
        "# Convolution with stride 1\n",
        "output_stride1 = torch.nn.functional.conv2d(input_tensor.unsqueeze(0).unsqueeze(0), kernel.unsqueeze(0).unsqueeze(0), stride=1)\n",
        "\n",
        "# Convolution with stride 2\n",
        "output_stride2 = torch.nn.functional.conv2d(input_tensor.unsqueeze(0).unsqueeze(0), kernel.unsqueeze(0).unsqueeze(0), stride=2)\n",
        "print(output_stride1)#The output will be a 4x4 tensor. Produces a detailed output, capturing fine-grained features.\n",
        "print(output_stride2)#The output will be a 2x2 tensor.Produces a coarser output, reducing computational cost but potentially losing some information.]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlGFWLZAS4K_",
        "outputId": "be020505-bcff-4e00-f851-bcad067ce85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0, -3, -3,  0],\n",
            "          [ 0, -3, -3,  0],\n",
            "          [ 0, -3, -3,  0],\n",
            "          [ 0, -3, -3,  0]]]])\n",
            "tensor([[[[ 0, -3],\n",
            "          [ 0, -3]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Best practices to consider when implementing convolution in PyTorch\n",
        "# Leverage PyTorch's  Module\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the convolutional layer\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
        "'''\n",
        "Batch Processing\n",
        "PyTorch's convolutional layers are designed to handle batches of images efficiently.\n",
        "Make sure that  your input tensor has the batch dimension as the first dimension.\n",
        "'''\n",
        "#Assuming a batch of 6 images\n",
        "input_tensor = torch.randn(6, 1, 6, 6)  # Batch, Channel, Height, Width\n",
        "output = conv_layer(input_tensor)\n",
        "if torch.cuda.is_available():#Here we verifying the GPU Availability\n",
        "    device = torch.device(\"cuda\")\n",
        "    input_tensor = input_tensor.to(device)\n",
        "    conv_layer = conv_layer.to(device)\n",
        "print(output)#You'll get an output tensor of the same shape: (16, 1, 6, 6).\n",
        "print(conv_layer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05EL5WsHT1DV",
        "outputId": "4e83c747-fe0c-41d8-8175-c432a1c57ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.3843,  0.1784,  0.8482,  0.3492, -0.1781,  0.4862],\n",
            "          [-0.6199,  1.4455,  0.4984, -1.3351,  0.3619, -0.3082],\n",
            "          [-0.0501, -0.0712,  0.7014,  0.7726, -0.9030,  0.3129],\n",
            "          [ 0.4047,  0.6088,  0.1137, -0.4287, -0.3144, -0.3336],\n",
            "          [ 0.4584,  0.0636, -0.2792,  0.3410, -0.2600,  0.1121],\n",
            "          [ 0.1846, -0.1797, -0.8022, -0.6623, -0.5133, -0.1768]]],\n",
            "\n",
            "\n",
            "        [[[-0.2413,  0.0882, -0.6934,  0.2262,  0.3605,  0.2944],\n",
            "          [-0.1279,  0.8842, -0.1650,  0.3514, -0.2671, -0.4250],\n",
            "          [ 0.3679, -0.6029, -1.4623, -0.0890,  0.7396,  1.0942],\n",
            "          [-0.0441,  0.3049,  0.3143,  0.4347,  0.2187,  1.0719],\n",
            "          [-0.1616,  0.6932, -0.2587,  0.6377,  0.0747,  1.4744],\n",
            "          [-0.4245,  0.3152,  0.5092, -0.3191,  0.5747,  0.8577]]],\n",
            "\n",
            "\n",
            "        [[[-0.7034, -0.9966, -0.7064, -1.1041, -0.4750, -0.4391],\n",
            "          [-0.8821, -0.4674, -0.6252,  0.2506,  0.3670,  0.9770],\n",
            "          [-0.6083, -0.3569,  0.3485,  0.1810,  0.7418, -0.1519],\n",
            "          [-0.1763, -1.1499, -1.1081,  0.6169,  1.4343,  1.1526],\n",
            "          [ 0.3878,  0.4026,  0.3878,  0.3237,  1.6913,  0.2796],\n",
            "          [ 1.1664,  0.2133, -0.1396,  0.1581,  0.8589,  0.9646]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0925,  0.1154,  0.1956,  0.1403,  0.1735, -0.0762],\n",
            "          [ 0.1013, -1.0926,  0.1892,  0.3786,  0.1696,  1.1940],\n",
            "          [ 0.1735, -0.1010,  0.4095,  0.9906, -0.0501, -0.3977],\n",
            "          [ 0.2083, -0.7399,  0.9187,  0.9396,  0.0753,  0.7001],\n",
            "          [-0.3184, -0.5819,  0.2831,  1.0179, -0.8332, -0.7543],\n",
            "          [-0.1611,  0.1624,  1.3182,  0.1751, -1.0083,  0.0237]]],\n",
            "\n",
            "\n",
            "        [[[ 0.5799,  1.2443,  0.3811,  0.7179,  0.2904,  0.0661],\n",
            "          [ 0.4397,  0.7379,  0.3949,  0.2237, -0.8159, -1.1774],\n",
            "          [-0.3717,  0.0140, -0.0197,  1.2037, -0.5529, -0.3131],\n",
            "          [-0.4733, -0.8539,  0.4371,  0.7758, -0.3219, -0.9434],\n",
            "          [ 0.0222, -0.3242,  0.8115,  0.8220,  0.2336,  0.5070],\n",
            "          [ 0.3402,  0.3628,  0.9712,  1.6455,  1.0212, -0.3952]]],\n",
            "\n",
            "\n",
            "        [[[ 0.6061,  0.1752,  0.4577,  0.9054,  0.1661,  0.5738],\n",
            "          [ 0.7373, -0.1661,  0.9027,  0.4917, -0.2978,  0.8712],\n",
            "          [ 0.4958, -0.5550,  0.0261,  1.8019,  0.5604,  0.0498],\n",
            "          [ 0.5480, -0.5185,  0.8008,  0.8087,  0.9978,  0.2673],\n",
            "          [ 0.7654, -0.4642,  0.1855,  1.9079,  1.5381, -0.6142],\n",
            "          [ 0.3532, -0.2907,  0.0624,  1.1056,  1.2951,  0.1719]]]],\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
          ]
        }
      ]
    }
  ]
}